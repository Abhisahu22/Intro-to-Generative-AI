{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "b1zc8iQ2POkm"
      },
      "source": [
        "**Importing Haystack library**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true,
          "base_uri": "https://localhost:8080/"
        },
        "id": "o4_-Dd78IK_q",
        "outputId": "910a34c8-4588-4098-d79e-13a0ba8bc4c0"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: pip in /usr/local/lib/python3.10/dist-packages (23.3.2)\n",
            "Requirement already satisfied: farm-haystack[colab,inference] in /usr/local/lib/python3.10/dist-packages (1.23.0)\n",
            "Requirement already satisfied: boilerpy3 in /usr/local/lib/python3.10/dist-packages (from farm-haystack[colab,inference]) (1.0.7)\n",
            "Requirement already satisfied: events in /usr/local/lib/python3.10/dist-packages (from farm-haystack[colab,inference]) (0.5)\n",
            "Requirement already satisfied: httpx in /usr/local/lib/python3.10/dist-packages (from farm-haystack[colab,inference]) (0.26.0)\n",
            "Requirement already satisfied: jsonschema in /usr/local/lib/python3.10/dist-packages (from farm-haystack[colab,inference]) (4.19.2)\n",
            "Requirement already satisfied: lazy-imports==0.3.1 in /usr/local/lib/python3.10/dist-packages (from farm-haystack[colab,inference]) (0.3.1)\n",
            "Requirement already satisfied: more-itertools in /usr/local/lib/python3.10/dist-packages (from farm-haystack[colab,inference]) (10.1.0)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from farm-haystack[colab,inference]) (3.2.1)\n",
            "Requirement already satisfied: pandas in /usr/local/lib/python3.10/dist-packages (from farm-haystack[colab,inference]) (1.5.3)\n",
            "Requirement already satisfied: pillow in /usr/local/lib/python3.10/dist-packages (from farm-haystack[colab,inference]) (9.0.0)\n",
            "Requirement already satisfied: platformdirs in /usr/local/lib/python3.10/dist-packages (from farm-haystack[colab,inference]) (4.1.0)\n",
            "Requirement already satisfied: posthog in /usr/local/lib/python3.10/dist-packages (from farm-haystack[colab,inference]) (3.3.1)\n",
            "Requirement already satisfied: prompthub-py==4.0.0 in /usr/local/lib/python3.10/dist-packages (from farm-haystack[colab,inference]) (4.0.0)\n",
            "Requirement already satisfied: pydantic<2 in /usr/local/lib/python3.10/dist-packages (from farm-haystack[colab,inference]) (1.10.13)\n",
            "Requirement already satisfied: quantulum3 in /usr/local/lib/python3.10/dist-packages (from farm-haystack[colab,inference]) (0.9.0)\n",
            "Requirement already satisfied: rank-bm25 in /usr/local/lib/python3.10/dist-packages (from farm-haystack[colab,inference]) (0.2.2)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from farm-haystack[colab,inference]) (2.31.0)\n",
            "Requirement already satisfied: requests-cache<1.0.0 in /usr/local/lib/python3.10/dist-packages (from farm-haystack[colab,inference]) (0.9.8)\n",
            "Requirement already satisfied: scikit-learn>=1.3.0 in /usr/local/lib/python3.10/dist-packages (from farm-haystack[colab,inference]) (1.3.2)\n",
            "Requirement already satisfied: sseclient-py in /usr/local/lib/python3.10/dist-packages (from farm-haystack[colab,inference]) (1.8.0)\n",
            "Requirement already satisfied: tenacity in /usr/local/lib/python3.10/dist-packages (from farm-haystack[colab,inference]) (8.2.3)\n",
            "Requirement already satisfied: tiktoken>=0.5.1 in /usr/local/lib/python3.10/dist-packages (from farm-haystack[colab,inference]) (0.5.2)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.10/dist-packages (from farm-haystack[colab,inference]) (4.66.1)\n",
            "Requirement already satisfied: transformers==4.35.2 in /usr/local/lib/python3.10/dist-packages (from farm-haystack[colab,inference]) (4.35.2)\n",
            "Requirement already satisfied: huggingface-hub>=0.5.0 in /usr/local/lib/python3.10/dist-packages (from farm-haystack[colab,inference]) (0.20.2)\n",
            "Requirement already satisfied: sentence-transformers>=2.2.0 in /usr/local/lib/python3.10/dist-packages (from farm-haystack[colab,inference]) (2.2.2)\n",
            "Requirement already satisfied: pyyaml<7.0,>=6.0 in /usr/local/lib/python3.10/dist-packages (from prompthub-py==4.0.0->farm-haystack[colab,inference]) (6.0.1)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from transformers==4.35.2->farm-haystack[colab,inference]) (3.13.1)\n",
            "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.10/dist-packages (from transformers==4.35.2->farm-haystack[colab,inference]) (1.23.5)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from transformers==4.35.2->farm-haystack[colab,inference]) (23.2)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.10/dist-packages (from transformers==4.35.2->farm-haystack[colab,inference]) (2023.6.3)\n",
            "Requirement already satisfied: tokenizers<0.19,>=0.14 in /usr/local/lib/python3.10/dist-packages (from transformers==4.35.2->farm-haystack[colab,inference]) (0.15.0)\n",
            "Requirement already satisfied: safetensors>=0.3.1 in /usr/local/lib/python3.10/dist-packages (from transformers==4.35.2->farm-haystack[colab,inference]) (0.4.1)\n",
            "Requirement already satisfied: sentencepiece!=0.1.92,>=0.1.91 in /usr/local/lib/python3.10/dist-packages (from transformers[sentencepiece,torch]==4.35.2; extra == \"inference\"->farm-haystack[colab,inference]) (0.1.99)\n",
            "Requirement already satisfied: protobuf in /usr/local/lib/python3.10/dist-packages (from transformers[sentencepiece,torch]==4.35.2; extra == \"inference\"->farm-haystack[colab,inference]) (3.20.3)\n",
            "Requirement already satisfied: torch!=1.12.0,>=1.10 in /usr/local/lib/python3.10/dist-packages (from transformers[sentencepiece,torch]==4.35.2; extra == \"inference\"->farm-haystack[colab,inference]) (2.1.0+cu121)\n",
            "Requirement already satisfied: accelerate>=0.20.3 in /usr/local/lib/python3.10/dist-packages (from transformers[sentencepiece,torch]==4.35.2; extra == \"inference\"->farm-haystack[colab,inference]) (0.26.1)\n",
            "Requirement already satisfied: fsspec>=2023.5.0 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub>=0.5.0->farm-haystack[colab,inference]) (2023.6.0)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub>=0.5.0->farm-haystack[colab,inference]) (4.5.0)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests->farm-haystack[colab,inference]) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->farm-haystack[colab,inference]) (3.6)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->farm-haystack[colab,inference]) (2.0.7)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->farm-haystack[colab,inference]) (2023.11.17)\n",
            "Requirement already satisfied: appdirs>=1.4.4 in /usr/local/lib/python3.10/dist-packages (from requests-cache<1.0.0->farm-haystack[colab,inference]) (1.4.4)\n",
            "Requirement already satisfied: attrs>=21.2 in /usr/local/lib/python3.10/dist-packages (from requests-cache<1.0.0->farm-haystack[colab,inference]) (23.2.0)\n",
            "Requirement already satisfied: cattrs>=22.2 in /usr/local/lib/python3.10/dist-packages (from requests-cache<1.0.0->farm-haystack[colab,inference]) (23.2.3)\n",
            "Requirement already satisfied: url-normalize>=1.4 in /usr/local/lib/python3.10/dist-packages (from requests-cache<1.0.0->farm-haystack[colab,inference]) (1.4.3)\n",
            "Requirement already satisfied: scipy>=1.5.0 in /usr/local/lib/python3.10/dist-packages (from scikit-learn>=1.3.0->farm-haystack[colab,inference]) (1.11.4)\n",
            "Requirement already satisfied: joblib>=1.1.1 in /usr/local/lib/python3.10/dist-packages (from scikit-learn>=1.3.0->farm-haystack[colab,inference]) (1.3.2)\n",
            "Requirement already satisfied: threadpoolctl>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from scikit-learn>=1.3.0->farm-haystack[colab,inference]) (3.2.0)\n",
            "Requirement already satisfied: torchvision in /usr/local/lib/python3.10/dist-packages (from sentence-transformers>=2.2.0->farm-haystack[colab,inference]) (0.16.0+cu121)\n",
            "Requirement already satisfied: nltk in /usr/local/lib/python3.10/dist-packages (from sentence-transformers>=2.2.0->farm-haystack[colab,inference]) (3.8.1)\n",
            "Requirement already satisfied: anyio in /usr/local/lib/python3.10/dist-packages (from httpx->farm-haystack[colab,inference]) (3.7.1)\n",
            "Requirement already satisfied: httpcore==1.* in /usr/local/lib/python3.10/dist-packages (from httpx->farm-haystack[colab,inference]) (1.0.2)\n",
            "Requirement already satisfied: sniffio in /usr/local/lib/python3.10/dist-packages (from httpx->farm-haystack[colab,inference]) (1.3.0)\n",
            "Requirement already satisfied: h11<0.15,>=0.13 in /usr/local/lib/python3.10/dist-packages (from httpcore==1.*->httpx->farm-haystack[colab,inference]) (0.14.0)\n",
            "Requirement already satisfied: jsonschema-specifications>=2023.03.6 in /usr/local/lib/python3.10/dist-packages (from jsonschema->farm-haystack[colab,inference]) (2023.12.1)\n",
            "Requirement already satisfied: referencing>=0.28.4 in /usr/local/lib/python3.10/dist-packages (from jsonschema->farm-haystack[colab,inference]) (0.32.1)\n",
            "Requirement already satisfied: rpds-py>=0.7.1 in /usr/local/lib/python3.10/dist-packages (from jsonschema->farm-haystack[colab,inference]) (0.16.2)\n",
            "Requirement already satisfied: python-dateutil>=2.8.1 in /usr/local/lib/python3.10/dist-packages (from pandas->farm-haystack[colab,inference]) (2.8.2)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.10/dist-packages (from pandas->farm-haystack[colab,inference]) (2023.3.post1)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.10/dist-packages (from posthog->farm-haystack[colab,inference]) (1.16.0)\n",
            "Requirement already satisfied: monotonic>=1.5 in /usr/local/lib/python3.10/dist-packages (from posthog->farm-haystack[colab,inference]) (1.6)\n",
            "Requirement already satisfied: backoff>=1.10.0 in /usr/local/lib/python3.10/dist-packages (from posthog->farm-haystack[colab,inference]) (2.2.1)\n",
            "Requirement already satisfied: inflect in /usr/local/lib/python3.10/dist-packages (from quantulum3->farm-haystack[colab,inference]) (7.0.0)\n",
            "Requirement already satisfied: num2words in /usr/local/lib/python3.10/dist-packages (from quantulum3->farm-haystack[colab,inference]) (0.5.13)\n",
            "Requirement already satisfied: psutil in /usr/local/lib/python3.10/dist-packages (from accelerate>=0.20.3->transformers[sentencepiece,torch]==4.35.2; extra == \"inference\"->farm-haystack[colab,inference]) (5.9.5)\n",
            "Requirement already satisfied: exceptiongroup>=1.1.1 in /usr/local/lib/python3.10/dist-packages (from cattrs>=22.2->requests-cache<1.0.0->farm-haystack[colab,inference]) (1.2.0)\n",
            "Requirement already satisfied: sympy in /usr/local/lib/python3.10/dist-packages (from torch!=1.12.0,>=1.10->transformers[sentencepiece,torch]==4.35.2; extra == \"inference\"->farm-haystack[colab,inference]) (1.12)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch!=1.12.0,>=1.10->transformers[sentencepiece,torch]==4.35.2; extra == \"inference\"->farm-haystack[colab,inference]) (3.1.2)\n",
            "Requirement already satisfied: triton==2.1.0 in /usr/local/lib/python3.10/dist-packages (from torch!=1.12.0,>=1.10->transformers[sentencepiece,torch]==4.35.2; extra == \"inference\"->farm-haystack[colab,inference]) (2.1.0)\n",
            "Requirement already satisfied: click in /usr/local/lib/python3.10/dist-packages (from nltk->sentence-transformers>=2.2.0->farm-haystack[colab,inference]) (8.1.7)\n",
            "Requirement already satisfied: docopt>=0.6.2 in /usr/local/lib/python3.10/dist-packages (from num2words->quantulum3->farm-haystack[colab,inference]) (0.6.2)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch!=1.12.0,>=1.10->transformers[sentencepiece,torch]==4.35.2; extra == \"inference\"->farm-haystack[colab,inference]) (2.1.3)\n",
            "Requirement already satisfied: mpmath>=0.19 in /usr/local/lib/python3.10/dist-packages (from sympy->torch!=1.12.0,>=1.10->transformers[sentencepiece,torch]==4.35.2; extra == \"inference\"->farm-haystack[colab,inference]) (1.3.0)\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "WARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\n",
            "WARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\n"
          ]
        }
      ],
      "source": [
        "%%bash\n",
        "\n",
        "pip install --upgrade pip\n",
        "pip install farm-haystack[colab,inference]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ftGLQ3Ed29-s"
      },
      "source": [
        "**Making data folder and importing files from Google Drive**\n",
        "\n",
        "---\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xya9EtIay1Ze",
        "outputId": "2a38fbed-829b-45e1-e787-9eee90c8bb45"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Drive already mounted at /content/gdrive; to attempt to forcibly remount, call drive.mount(\"/content/gdrive\", force_remount=True).\n",
            "The 'data' folder has been created at '/content/data'.\n",
            "The files 'train.json' and 'test.json' have been copied to '/content/data'.\n"
          ]
        }
      ],
      "source": [
        "import os\n",
        "from google.colab import drive\n",
        "\n",
        "# Mount Google Drive\n",
        "drive.mount('/content/gdrive')\n",
        "\n",
        "# Create a folder named 'data' in Google Colab\n",
        "folder_name = \"data\"\n",
        "folder_path = os.path.join('/content', folder_name)\n",
        "\n",
        "if not os.path.exists(folder_path):\n",
        "    os.makedirs(folder_path)\n",
        "\n",
        "print(f\"The '{folder_name}' folder has been created at '{folder_path}'.\")\n",
        "\n",
        "# Specify the file names in your Google Drive\n",
        "file1_name = \"train.json\"\n",
        "file2_name = \"test.json\"\n",
        "\n",
        "# Specify the paths to the files in your Google Drive\n",
        "file1_drive_path = \"/content/gdrive/MyDrive/\" + file1_name\n",
        "file2_drive_path = \"/content/gdrive/MyDrive/\" + file2_name\n",
        "\n",
        "# Specify the paths to copy the files in Google Colab\n",
        "file1_colab_path = os.path.join(folder_path, file1_name)\n",
        "file2_colab_path = os.path.join(folder_path, file2_name)\n",
        "\n",
        "# Copy the files from Google Drive to Google Colab\n",
        "!cp \"$file1_drive_path\" \"$file1_colab_path\"\n",
        "!cp \"$file2_drive_path\" \"$file2_colab_path\"\n",
        "\n",
        "print(f\"The files '{file1_name}' and '{file2_name}' have been copied to '{folder_path}'.\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "8sZqypdyIn18"
      },
      "outputs": [],
      "source": [
        "from haystack.telemetry import tutorial_running\n",
        "\n",
        "tutorial_running(2)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "eQiNigGjPfNn"
      },
      "source": [
        "**Model to use**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "D1xC3EXNIwj_"
      },
      "outputs": [],
      "source": [
        "model_name = \"dmis-lab/biobert-large-cased-v1.1-squad\""
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EgFrJPJFEEwj"
      },
      "source": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "seJ3tkiUPkcF"
      },
      "source": [
        "**Importing FARMReader class**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5v_I4ugeI1UB",
        "outputId": "5827b84e-3c8e-4ed0-f191-fec4a2ca3eaa"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/huggingface_hub/utils/_token.py:88: UserWarning: \n",
            "The secret `HF_TOKEN` does not exist in your Colab secrets.\n",
            "To authenticate with the Hugging Face Hub, create a token in your settings tab (https://huggingface.co/settings/tokens), set it as secret in your Google Colab and restart your session.\n",
            "You will be able to reuse this secret in all of your notebooks.\n",
            "Please note that authentication is recommended but still optional to access public models or datasets.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/torch/_utils.py:831: UserWarning: TypedStorage is deprecated. It will be removed in the future and UntypedStorage will be the only storage class. This should only matter to you if you are using storages directly.  To access UntypedStorage directly, use tensor.untyped_storage() instead of tensor.storage()\n",
            "  return self.fget.__get__(instance, owner)()\n"
          ]
        }
      ],
      "source": [
        "from haystack.nodes import FARMReader\n",
        "\n",
        "reader = FARMReader(model_name_or_path=model_name , use_gpu=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "H1b3Vk-qI19F"
      },
      "outputs": [],
      "source": [
        "data_dir = \"data/\""
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GD8AOyEG3lsu"
      },
      "source": [
        "**Training Model**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4tmmJWH7I5Vt",
        "outputId": "247b00a0-969b-42ec-a840-d8ecc6b5e41d"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Preprocessing dataset: 100%|██████████| 1/1 [00:00<00:00, 12.90 Dicts/s]\n",
            "Train epoch 0/3 (Cur. train loss: 0.0000):   0%|          | 0/31 [00:00<?, ?it/s]"
          ]
        }
      ],
      "source": [
        "reader.train(data_dir=data_dir, train_filename=\"train.json\", use_gpu=True, n_epochs=4, save_dir=\"my_model\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jS4mw-CWI82U",
        "outputId": "7d76feb1-b591-4c9e-a92d-2acf57b5e214"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "WARNING:haystack.modeling.model.prediction_head:Some unused parameters are passed to the QuestionAnsweringHead. Might not be a problem. Params: {\"training\": false, \"num_labels\": 2, \"ph_output_type\": \"per_token_squad\", \"model_type\": \"span_classification\", \"label_tensor_name\": \"question_answering_label_ids\", \"label_list\": [\"start_token\", \"end_token\"], \"metric\": \"squad\", \"name\": \"QuestionAnsweringHead\"}\n"
          ]
        }
      ],
      "source": [
        "model = FARMReader(model_name_or_path=\"my_model\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1SCkWTx53q68"
      },
      "source": [
        "**Evaluating result**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NnTN7wGgK-FQ",
        "outputId": "146c104c-6d7d-4724-a8b3-6a2948087233"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "WARNING:haystack.nodes.reader.farm:FARMReader.eval_on_file() uses a slightly different evaluation approach than `Pipeline.eval()`:\n",
            "- instead of giving you full control over which labels to use, this method always returns three types of metrics: combined (no suffix), text_answer ('_text_answer' suffix) and no_answer ('_no_answer' suffix) metrics.\n",
            "- instead of comparing predictions with labels on a string level, this method compares them on a token-ID level. This makes it unable to do any string normalization (e.g. normalize whitespaces) beforehand.\n",
            "Hence, results might slightly differ from those of `Pipeline.eval()`\n",
            ".If you are just about starting to evaluate your model consider using `Pipeline.eval()` instead.\n",
            "Preprocessing dataset: 100%|██████████| 1/1 [00:00<00:00, 34.52 Dicts/s]\n",
            "Evaluating: 100%|██████████| 2/2 [00:03<00:00,  1.76s/it]\n"
          ]
        }
      ],
      "source": [
        "\n",
        "reader_eval_results = model.eval_on_file(\"data/\", \"test.json\", device=\"cuda\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-ApouBtC31WV"
      },
      "source": [
        "**Scores**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MgExgmxuLSdf",
        "outputId": "6619b0ae-dbe2-402a-9c11-cb476a7ea999"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "{'EM': 50.0,\n",
              " 'f1': 59.635416666666664,\n",
              " 'top_n_accuracy': 81.25,\n",
              " 'top_n': 4,\n",
              " 'EM_text_answer': 33.33333333333333,\n",
              " 'f1_text_answer': 46.18055555555556,\n",
              " 'top_n_accuracy_text_answer': 75.0,\n",
              " 'top_n_EM_text_answer': 58.333333333333336,\n",
              " 'top_n_f1_text_answer': 71.18055555555554,\n",
              " 'Total_text_answer': 12,\n",
              " 'EM_no_answer': 100.0,\n",
              " 'f1_no_answer': 100.0,\n",
              " 'top_n_accuracy_no_answer': 100.0,\n",
              " 'Total_no_answer': 4}"
            ]
          },
          "execution_count": 10,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "reader_eval_results"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vMhvy0dU4dNG"
      },
      "source": [
        "**Question Answering**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "o7VrBhQhMEzT",
        "outputId": "b9287eec-8408-4a69-8185-92e6c51527cc"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00,  2.60 Batches/s]\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "[<Answer {'answer': 'overweight', 'type': 'extractive', 'score': 0.9938992261886597, 'context': 'NDICATION FOR PROCEDURE: , This is a 30-year-old female, who has been overweight for many years.  She has tried many different diets, but is unsuccess', 'offsets_in_document': [{'start': 303, 'end': 313}], 'offsets_in_context': [{'start': 70, 'end': 80}], 'document_ids': ['78d4422fa129d25a94d7ed4250af016d'], 'meta': {}}>,\n",
              " <Answer {'answer': 'reverse Trendelenburg', 'type': 'extractive', 'score': 1.990109922189731e-05, 'context': 'y for my small bowel to go antecolic.  I then put the patient in reverse Trendelenburg.  I placed a liver retractor, identified, and dissected the ang', 'offsets_in_document': [{'start': 2612, 'end': 2633}], 'offsets_in_context': [{'start': 65, 'end': 86}], 'document_ids': ['78d4422fa129d25a94d7ed4250af016d'], 'meta': {}}>,\n",
              " <Answer {'answer': 'bladder decompression.  The abdomen was then prepped and draped in standard sterile surgical fashion.', 'type': 'extractive', 'score': 1.8167605958296917e-05, 'context': ' catheter was placed for bladder decompression.  The abdomen was then prepped and draped in standard sterile surgical fashion.  Marcaine was then inje', 'offsets_in_document': [{'start': 855, 'end': 956}], 'offsets_in_context': [{'start': 25, 'end': 126}], 'document_ids': ['78d4422fa129d25a94d7ed4250af016d'], 'meta': {}}>]"
            ]
          },
          "execution_count": 11,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "context = \"\"\"PREOPERATIVE DIAGNOSIS: , Morbid obesity.,POSTOPERATIVE DIAGNOSIS:  ,Morbid obesity.,PROCEDURE: , Laparoscopic antecolic antegastric Roux-en-Y gastric bypass with EEA anastomosis.,ANESTHESIA: , General with endotracheal intubation.,INDICATION FOR PROCEDURE: , This is a 30-year-old female, who has been overweight for many years.  She has tried many different diets, but is unsuccessful.  She has been to our Bariatric Surgery Seminar, received some handouts, and signed the consent.  The risks and benefits of the procedure have been explained to the patient.,PROCEDURE IN DETAIL:  ,The patient was taken to the operating room and placed supine on the operating room table.  All pressure points were carefully padded.  She was given general anesthesia with endotracheal intubation.  SCD stockings were placed on both legs.  Foley catheter was placed for bladder decompression.  The abdomen was then prepped and draped in standard sterile surgical fashion.  Marcaine was then injected through umbilicus.  A small incision was made.  A Veress needle was introduced into the abdomen.  CO2 insufflation was done to a maximum pressure of 15 mmHg.  A 12-mm VersaStep port was placed through the umbilicus.  I then placed a 5-mm port just anterior to the midaxillary line and just subcostal on the right side.  I placed another 5-mm port in the midclavicular line just subcostal on the right side, a few centimeters below and medial to that, I placed a 12-mm VersaStep port.  On the left side, just anterior to the midaxillary line and just subcostal, I placed a 5-mm port.  A few centimeters below and medial to that, I placed a 15-mm port.  I began by lifting up the omentum and identifying the transverse colon and lifting that up and thereby identifying my ligament of Treitz.  I ran the small bowel down approximately 40 cm and divided the small bowel with a white load GIA stapler.  I then divided the mesentery all the way down to the base of the mesentery with a LigaSure device.  I then ran the distal bowel down, approximately 100 cm, and at 100 cm, I made a hole at the antimesenteric portion of the Roux limb and a hole in the antimesenteric portion of the duodenogastric limb, and I passed a 45 white load stapler and fired a stapler creating a side-to-side anastomosis.  I reapproximated the edges of the defect.  I lifted it up and stapled across it with another white load stapler.  I then closed the mesenteric defect with interrupted Surgidac sutures.  I divided the omentum all the way down to the colon in order to create a passageway for my small bowel to go antecolic.  I then put the patient in reverse Trendelenburg.  I placed a liver retractor, identified, and dissected the angle of His.  I then dissected on the lesser curve, approximately 2.5 cm below the gastroesophageal junction, and got into a lesser space.  I fired transversely across the stomach with a 45 blue load stapler.  I then used two fires of the 60 blue load with SeamGuard to go up into my angle of His, thereby creating my gastric pouch.  I then made a hole at the base of the gastric pouch and had Anesthesia remove the bougie and place the OG tube connected to the anvil.  I pulled the anvil into place, and I then opened up my 15-mm port site and passed my EEA stapler.  I passed that in the end of my Roux limb and had the spike come out antimesenteric.  I joined the spike with the anvil and fired a stapler creating an end-to-side anastomosis, then divided across the redundant portion of my Roux limb with a white load GI stapler, and removed it with an Endocatch bag.  I put some additional 2-0 Vicryl sutures in the anastomosis for further security.  I then placed a bowel clamp across the bowel.  I went above and passed an EGD scope into the mouth down to the esophagus and into the gastric pouch.  I distended gastric pouch with air.  There was no air leak seen.  I could pass the scope easily through the anastomosis.  There was no bleeding seen through the scope.  We closed the 15-mm port site with interrupted 0 Vicryl suture utilizing Carter-Thomason.  I copiously irrigated out that incision with about 2 L of saline.  I then closed the skin of all incisions with running Monocryl.  Sponge, instrument, and needle counts were correct at the end of the case.  The patient tolerated the procedure well without any complications.\"\"\"\n",
        "ques='Does the patient have any complaints?'\n",
        "ans = model.predict_on_texts(ques,[context])\n",
        "ans['answers']"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MPq22l7CNHSw",
        "outputId": "66fe7701-1ece-4fbb-fb3a-27c28813c85a"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00,  2.62 Batches/s]\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "[<Answer {'answer': 'female', 'type': 'extractive', 'score': 0.9382225275039673, 'context': 'otracheal intubation.,INDICATION FOR PROCEDURE: , This is a 30-year-old female, who has been overweight for many years.  She has tried many different ', 'offsets_in_document': [{'start': 282, 'end': 288}], 'offsets_in_context': [{'start': 72, 'end': 78}], 'document_ids': ['78d4422fa129d25a94d7ed4250af016d'], 'meta': {}}>,\n",
              " <Answer {'answer': '.', 'type': 'extractive', 'score': 7.0621713348373305e-06, 'context': 'essure of 15 mmHg.  A 12-mm VersaStep port was placed through the umbilicus.  I then placed a 5-mm port just anterior to the midaxillary line and just', 'offsets_in_document': [{'start': 1199, 'end': 1200}], 'offsets_in_context': [{'start': 75, 'end': 76}], 'document_ids': ['78d4422fa129d25a94d7ed4250af016d'], 'meta': {}}>,\n",
              " <Answer {'answer': '-', 'type': 'extractive', 'score': 5.905879334022757e-06, 'context': '.  I joined the spike with the anvil and fired a stapler creating an end-to-side anastomosis, then divided across the redundant portion of my Roux lim', 'offsets_in_document': [{'start': 3421, 'end': 3422}], 'offsets_in_context': [{'start': 75, 'end': 76}], 'document_ids': ['78d4422fa129d25a94d7ed4250af016d'], 'meta': {}}>]"
            ]
          },
          "execution_count": 12,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "ques2='What is the gender of the Patient'\n",
        "ans = model.predict_on_texts(ques2,[context])\n",
        "ans['answers']"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bto4ISLK4kAA"
      },
      "source": [
        "**Making our Pipeline**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DR-0TxuAMsAb",
        "outputId": "bfedd8ce-5f27-4f18-ecd3-1f146340f227"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00,  2.59 Batches/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "'Query: What is the gender of the Patient'\n",
            "'Answers:'\n",
            "[   {   'answer': 'female',\n",
            "        'context': 'otracheal intubation.,INDICATION FOR PROCEDURE: , This is '\n",
            "                   'a 30-year-old female, who has been overweight for many '\n",
            "                   'years.  She has tried many different ',\n",
            "        'score': 0.9382225275039673},\n",
            "    {   'answer': '.',\n",
            "        'context': 'essure of 15 mmHg.  A 12-mm VersaStep port was placed '\n",
            "                   'through the umbilicus.  I then placed a 5-mm port just '\n",
            "                   'anterior to the midaxillary line and just',\n",
            "        'score': 7.0621713348373305e-06},\n",
            "    {   'answer': '-',\n",
            "        'context': '.  I joined the spike with the anvil and fired a stapler '\n",
            "                   'creating an end-to-side anastomosis, then divided across '\n",
            "                   'the redundant portion of my Roux lim',\n",
            "        'score': 5.905879334022757e-06}]\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n"
          ]
        }
      ],
      "source": [
        "\n",
        "from haystack import Pipeline, Document\n",
        "from haystack.utils import print_answers\n",
        "\n",
        "p = Pipeline()\n",
        "p.add_node(component=model, name=\"Reader\", inputs=[\"Query\"])\n",
        "res = p.run(\n",
        "    query=ques2, documents=[Document(content=context)]\n",
        ")\n",
        "print_answers(res,details=\"medium\")"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}